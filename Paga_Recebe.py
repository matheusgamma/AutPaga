import streamlit as st
import pandas as pd
from io import BytesIO
import numpy as np
import yfinance as yf


st.set_page_config(page_title="Unifica√ß√£o de Opera√ß√µes", layout="wide")


# ==============================
# Fun√ß√µes auxiliares
# ==============================

# =========================
# NORMALIZA√á√ÉO DE PRE√áO (centavos / lote)
# =========================
def normalizar_preco(p):
    if pd.isna(p):
        return p
    # pre√ßos absurdos pra a√ß√£o brasileira ‚Üí provavelmente centavos ou lote
    if p > 1000:
        return p / 100
    return p

def carregar_arquivo(uploaded_file) -> pd.DataFrame | None:
    """L√™ CSV ou Excel e retorna DataFrame."""
    if uploaded_file is None:
        return None

    nome = uploaded_file.name.lower()

    try:
        if nome.endswith(".csv"):
            df = pd.read_csv(uploaded_file, sep=";", decimal=",")
        else:
            df = pd.read_excel(uploaded_file)
        return df
    except Exception as e:
        st.error(f"Erro ao ler o arquivo {uploaded_file.name}: {e}")
        return None


def primeira_nao_nula(serie: pd.Series):
    """Retorna o primeiro valor n√£o nulo da s√©rie, ou None."""
    serie_drop = serie.dropna()
    return serie_drop.iloc[0] if not serie_drop.empty else None

@st.cache_data(show_spinner=False, ttl=60 * 30)
def get_preco_mercado_yf(ativo: str) -> float | None:
    """
    Puxa o pre√ßo de mercado via yfinance.
    Para B3, tenta sufixo .SA (ex: RAIL3 -> RAIL3.SA).
    """
    if not ativo or pd.isna(ativo):
        return None

    ativo = str(ativo).strip().upper()

    # tenta como veio
    tickers_try = [ativo]

    # se parece ticker B3, tenta .SA
    if ativo.endswith(("3", "4", "11", "5", "6")) and ".SA" not in ativo:
        tickers_try.append(f"{ativo}.SA")

    for t in tickers_try:
        try:
            tk = yf.Ticker(t)
            # fast_info costuma ser mais r√°pido quando dispon√≠vel
            price = None
            if hasattr(tk, "fast_info") and tk.fast_info:
                price = tk.fast_info.get("last_price", None)

            if price is None:
                hist = tk.history(period="5d")
                if hist is not None and not hist.empty:
                    price = float(hist["Close"].dropna().iloc[-1])

            if price is not None and not (isinstance(price, float) and np.isnan(price)):
                return float(price)
        except Exception:
            continue

    return None




def br_to_float(x):
    """
    Converte n√∫mero vindo como '20,67' ou '20.67' para float.
    """
    if pd.isna(x):
        return np.nan
    if isinstance(x, (int, float, np.number)):
        return float(x)
    s = str(x).strip()
    if s == "":
        return np.nan
    # remove milhares e troca v√≠rgula por ponto quando for padr√£o BR
    s = s.replace(".", "").replace(",", ".")
    try:
        return float(s)
    except Exception:
        return np.nan



def processar_dados(df_assessores: pd.DataFrame, df_ops: pd.DataFrame, df_dash: pd.DataFrame) -> pd.DataFrame:
    """
    Unifica opera√ß√µes multi-pernas da planilha padr√£o, cruza com a base de assessores,
    cruza com o Dash (Pre√ßo de Abertura e Pre√ßo de Mercado) e calcula colunas finais.
    """

    # ==============================
    # Helpers locais
    # ==============================
    def br_to_float(x):
        if pd.isna(x):
            return pd.NA
        if isinstance(x, (int, float)):
            return float(x)
        s = str(x).strip()
        if s == "":
            return pd.NA
        s = s.replace("R$", "").replace(" ", "")

        has_comma = "," in s
        has_dot = "." in s
        try:
            if has_comma and has_dot:
                # decide qual √© o decimal olhando o √∫ltimo separador
                if s.rfind(",") > s.rfind("."):
                    # BR: 1.234,56
                    s = s.replace(".", "").replace(",", ".")
                else:
                    # US: 1,234.56
                    s = s.replace(",", "")
            elif has_comma and not has_dot:
                # 149,30
                s = s.replace(",", ".")
            # else: 149.30 ou 14930 -> mant√©m
            return float(s)
        except Exception:
            return pd.NA

    def norm_date(x):
        dt = pd.to_datetime(x, errors="coerce", dayfirst=True)
        if pd.isna(dt):
            return pd.NaT
        return dt.date()

    # ==============================
    # Validar colunas
    # ==============================
    cols_assessores_obrig = {"Conta", "Nome", "Assessor"}
    cols_ops_obrig = {
        "Data_Opera√ß√£o",
        "Conta_Cliente",
        "Tipo Opera√ß√£o",
        "Tipo Op√ß√£o",
        "Ativo",
        "Pre√ßo Exerc√≠cio",
        "Quantidade",
        "Fixing",
        "Estrutura",
        "Ref",
        "Bid(+)/Offer(-)",
        "C√≥digo do Produto",
    }
    cols_dash_obrig = {"Conta", "Ativo", "Data de Fixing", "Pre√ßo de Abertura", "Pre√ßo de Mercado"}

    faltando_ass = cols_assessores_obrig - set(df_assessores.columns)
    faltando_ops = cols_ops_obrig - set(df_ops.columns)
    faltando_dash = cols_dash_obrig - set(df_dash.columns)

    if faltando_ass:
        raise ValueError(f"Faltam colunas na base de assessores: {faltando_ass}")
    if faltando_ops:
        raise ValueError(f"Faltam colunas na planilha padr√£o: {faltando_ops}")
    if faltando_dash:
        raise ValueError(f"Faltam colunas no Dash: {faltando_dash}")

    df_ops = df_ops.copy()
    df_assessores = df_assessores.copy()
    df_dash = df_dash.copy()

    # ==============================
    # 1) Unificar opera√ß√µes (planilha padr√£o)
    # ==============================
    group_cols = [
        "Data_Opera√ß√£o",
        "Conta_Cliente",
        "Ativo",
        "Fixing",
        "Estrutura",
        "Ref",
        "C√≥digo do Produto",
    ]

    agg_dict = {
        "Tipo Opera√ß√£o": lambda x: ", ".join(sorted(set(x.dropna()))),
        "Tipo Op√ß√£o": lambda x: ", ".join(sorted(set(x.dropna()))),
        "Pre√ßo Exerc√≠cio": "min",
        "Quantidade": "max",
        "Bid(+)/Offer(-)": "sum",
    }

    df_grouped = (
        df_ops
        .groupby(group_cols, dropna=False)
        .agg(agg_dict)
        .reset_index()
    )

    # ==============================
    # 2) Cruzar com base de assessores
    # ==============================
    df_merged = df_grouped.merge(
        df_assessores[["Conta", "Nome", "Assessor"]],
        left_on="Conta_Cliente",
        right_on="Conta",
        how="left",
    )

    df_merged = df_merged.rename(columns={
        "Nome": "Nome Cliente",
        "Bid(+)/Offer(-)": "Paga/Recebe",
    })

    # ==============================
    # 3) Normalizar tipos e fazer merge com Dash
    # ==============================
    df_merged["Conta_Cliente"] = pd.to_numeric(df_merged["Conta_Cliente"], errors="coerce")
    df_merged["Ativo"] = df_merged["Ativo"].astype(str).str.strip().str.upper()
    df_merged["Fixing_norm"] = df_merged["Fixing"].apply(norm_date)

    df_merged["Pre√ßo Exerc√≠cio"] = df_merged["Pre√ßo Exerc√≠cio"].apply(br_to_float)
    df_merged["Quantidade"] = df_merged["Quantidade"].apply(br_to_float)
    df_merged["Paga/Recebe"] = df_merged["Paga/Recebe"].apply(br_to_float)

    df_dash["Conta"] = pd.to_numeric(df_dash["Conta"], errors="coerce")
    df_dash["Ativo"] = df_dash["Ativo"].astype(str).str.strip().str.upper()
    df_dash["Fixing_norm"] = df_dash["Data de Fixing"].apply(norm_date)
    df_dash["Pre√ßo Abertura"] = df_dash["Pre√ßo de Abertura"].apply(br_to_float)
    df_dash["Pre√ßo mercado"] = df_dash["Pre√ßo de Mercado"].apply(br_to_float)

    # Se o Dash tiver duplicidade por Conta+Ativo+Fixing, pegamos a primeira ocorr√™ncia
    dash_keys = ["Conta", "Ativo", "Fixing_norm"]
    df_dash_min = (
        df_dash[dash_keys + ["Pre√ßo Abertura", "Pre√ßo mercado"]]
        .dropna(subset=dash_keys)
        .drop_duplicates(dash_keys)
    )

    df_merged = df_merged.merge(
        df_dash_min,
        left_on=["Conta_Cliente", "Ativo", "Fixing_norm"],
        right_on=["Conta", "Ativo", "Fixing_norm"],
        how="left",
    )

    # ==============================
    # 4) Colunas finais
    # ==============================
    # Paga/Recebe em texto
    df_merged["Cliente_Paga_Recebe"] = df_merged["Paga/Recebe"].apply(
        lambda x: "PAGA" if pd.notnull(x) and x < 0 else ("RECEBE" if pd.notnull(x) and x > 0 else "NEUTRO")
    )

    # Pre√ßo final = Pre√ßo mercado + Bid
    df_merged["Pre√ßo final"] = df_merged["Pre√ßo mercado"] + df_merged["Paga/Recebe"]

    # Lucro saindo (%) = (Pre√ßo final / Pre√ßo Abertura - 1) * 100
    df_merged["Lucro saindo"] = ((df_merged["Pre√ßo final"] / df_merged["Pre√ßo Abertura"]) - 1) * 100

    # Bid total = Quantidade * Bid
    df_merged["Bid total"] = df_merged["Quantidade"] * df_merged["Paga/Recebe"]

    # Nocional entrada = Pre√ßo Abertura * Quantidade
    df_merged["Nocional entrada"] = df_merged["Pre√ßo Abertura"] * df_merged["Quantidade"]

    # Nocional saida = Pre√ßo final * Quantidade
    df_merged["Nocional saida"] = df_merged["Pre√ßo final"] * df_merged["Quantidade"]

    # Lucro $ Saindo hoje = Nocional saida - Nocional entrada
    df_merged["Lucro $ Saindo hoje"] = df_merged["Nocional saida"] - df_merged["Nocional entrada"]

    # ==============================
    # 5) Sele√ß√£o/ordem das colunas (como voc√™ pediu)
    # ==============================
    colunas_saida = [
        "Data_Opera√ß√£o",
        "Conta_Cliente",
        "Assessor",
        "Nome Cliente",
        "Ativo",
        "Pre√ßo Exerc√≠cio",
        "Quantidade",
        "Fixing",
        "Estrutura",
        "Paga/Recebe",
        "Cliente_Paga_Recebe",
        "Pre√ßo Abertura",
        "Pre√ßo mercado",
        "Pre√ßo final",
        "Lucro saindo",
        "Bid total",
        "Nocional entrada",
        "Nocional saida",
        "Lucro $ Saindo hoje",
    ]

    # S√≥ por seguran√ßa (se alguma coluna faltar)
    colunas_saida = [c for c in colunas_saida if c in df_merged.columns]

    return df_merged[colunas_saida]



def gerar_excel_para_download(df: pd.DataFrame) -> BytesIO:
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False, sheet_name="Resultado")
    output.seek(0)
    return output


# ==============================
# Interface Streamlit
# ==============================

st.title("Unifica√ß√£o de Opera√ß√µes - Renova")

st.markdown(
    """
    **Fluxo:**
    1. Envie a **Base de Assessores**
    2. Envie a **Planilha Padr√£o de Opera√ß√µes**  
    3. Clique em **Processar** para unificar opera√ß√µes  
    """
)

col1, col2, col3 = st.columns(3)

with col1:
    file_assessores = st.file_uploader(
        "üìÇ Base de Assessores",
        type=["xlsx", "xls", "csv"],
        key="file_assessores",
    )

with col2:
    file_ops = st.file_uploader(
        "üìÇ Planilha Padr√£o de Opera√ß√µes",
        type=["xlsx", "xls", "csv"],
        key="file_ops",
    )

with col3:
    file_dash = st.file_uploader(
        "üìÇ Dash Pre√ßo de Abertura",
        type=["xlsx", "xls", "csv"],
        key="file_dash",
    )



if st.button("üöÄ Processar"):
    if not file_assessores or not file_ops or not file_dash:
        st.warning("Envie as **tr√™s** planilhas antes de processar.")
    else:
        df_assessores = carregar_arquivo(file_assessores)
        df_ops = carregar_arquivo(file_ops)
        df_dash = carregar_arquivo(file_dash)

        if df_assessores is None or df_ops is None or df_dash is None:
            st.stop()

        try:
            df_resultado = processar_dados(df_assessores, df_ops, df_dash)
        except Exception as e:
            st.error(f"Erro ao processar os dados: {e}")
            st.stop()

        st.success("Processamento conclu√≠do com sucesso! ‚úÖ")
        st.subheader("Pr√©via do Resultado Unificado")
        st.dataframe(df_resultado.head(100))

        excel_bytes = gerar_excel_para_download(df_resultado)

        st.download_button(
            label="üì• Baixar resultado em Excel",
            data=excel_bytes,
            file_name="resultado_unificado.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

